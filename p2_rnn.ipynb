{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juAFOVa0rck3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, metrics\n",
        "import pandas as pd\n",
        "import requests\n",
        "import gzip\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set random_seed. This will keep random things the same through multiple experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.utils.set_random_seed(812)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnJg07dtrck4"
      },
      "outputs": [],
      "source": [
        "def read_gzipped_json_from_url(url):\n",
        "    # Send a HTTP request to the URL\n",
        "    response = requests.get(url)\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Use gzip to decompress the content\n",
        "        with gzip.GzipFile(fileobj=io.BytesIO(response.content)) as gz:\n",
        "            # Read the JSON lines file and convert to a DataFrame\n",
        "            df = pd.read_json(gz, lines=True)\n",
        "        return df\n",
        "    else:\n",
        "        print(f\"Failed to retrieve data: status code {response.status_code}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ut-2Py4Erck4"
      },
      "outputs": [],
      "source": [
        "# URL to the gzipped JSON file\n",
        "url = 'https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Luxury_Beauty_5.json.gz'\n",
        "url2 = 'https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFiles/AMAZON_FASHION.json.gz'\n",
        "luxury_df = read_gzipped_json_from_url(url).reset_index(drop=True)\n",
        "amazon_fashion_df = read_gzipped_json_from_url(url2).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBmiag6dxykB"
      },
      "outputs": [],
      "source": [
        "fashion_df = amazon_fashion_df[['overall','reviewText']]\n",
        "luxury_df = luxury_df[['overall','reviewText']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ms_sngLrck4",
        "outputId": "556731f9-7856-4094-987c-c844fc5654e9"
      },
      "outputs": [],
      "source": [
        "# Display the first few rows of the DataFrame\n",
        "if fashion_df is not None:\n",
        "    print(fashion_df.head())\n",
        "if luxury_df is not None:\n",
        "    print(luxury_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "cXYVSCj4ws7x",
        "outputId": "1c37988d-c913-4c6b-eddf-6a0c9e1341b2"
      },
      "outputs": [],
      "source": [
        "print(fashion_df.describe())\n",
        "print(luxury_df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vm6RFaq-0EmM"
      },
      "outputs": [],
      "source": [
        "fashion_df = fashion_df.dropna()\n",
        "luxury_df = luxury_df.dropna()\n",
        "print(fashion_df.describe())\n",
        "print(luxury_df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMJOc4uqJHtE",
        "outputId": "ca9bc6b6-a971-4372-88a6-462f2f53f696"
      },
      "outputs": [],
      "source": [
        "rating_counts_fashion = fashion_df['overall'].value_counts()\n",
        "rating_counts_luxury = luxury_df['overall'].value_counts()\n",
        "print(rating_counts_fashion)\n",
        "print(rating_counts_luxury)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Both datasets are very imbalanced. The training and validation set will be balanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c9HHhATKcQq"
      },
      "source": [
        "### Creating a smaller and more balanced dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Starts experiments with 10000 samples of each rating. So 50000 in total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-cX8xdJKbKq",
        "outputId": "24763d48-7256-47b7-a0ad-feb517fc602e"
      },
      "outputs": [],
      "source": [
        "number_each_rating = 10000\n",
        "balanced_df = fashion_df.groupby('overall').head(number_each_rating)\n",
        "balanced_counts = balanced_df['overall'].value_counts()\n",
        "print(balanced_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting tager and splitting data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZDnrDALrck5"
      },
      "outputs": [],
      "source": [
        "y = balanced_df['overall']\n",
        "\n",
        "df_xtrain, df_xval, df_ytrain, df_yval = train_test_split(balanced_df, y, test_size=0.1, random_state=42, stratify=y)\n",
        "df_xtrain = df_xtrain.reset_index(drop=True)\n",
        "df_xval = df_xval.reset_index(drop=True)\n",
        "df_ytrain = df_ytrain.reset_index(drop=True)\n",
        "df_yval = df_yval.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_ytrain.value_counts())\n",
        "print(df_yval.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_xtrain.head())\n",
        "print(df_xval.head())\n",
        "print(df_ytrain.head())\n",
        "print(df_yval.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test = luxury_df['overall']\n",
        "x_test = luxury_df['reviewText']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsxNz7RDv5Dc",
        "outputId": "9a18620f-6096-49cc-a5a9-0f7a13a59234"
      },
      "outputs": [],
      "source": [
        "review_lengths = df_xtrain['reviewText'].apply(len)\n",
        "\n",
        "min_length = review_lengths.min()\n",
        "\n",
        "max_length = review_lengths.max()\n",
        "\n",
        "mean_length = review_lengths.mean()\n",
        "\n",
        "median_length = review_lengths.median()\n",
        "\n",
        "print('90th Percentile Length:',review_lengths.quantile(q = 0.9))\n",
        "print(\"Minimum Length:\", min_length)\n",
        "print(\"Maximum Length:\", max_length)\n",
        "print(\"Mean Length:\", mean_length)\n",
        "print(\"Median Length:\", median_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuFNCyWx1LXD"
      },
      "source": [
        "Min and max length\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ1oweTF0wuD",
        "outputId": "69fe1f21-237f-4976-babc-1156652e3285"
      },
      "outputs": [],
      "source": [
        "min_length_index = review_lengths.idxmin()\n",
        "\n",
        "max_length_index = review_lengths.idxmax()\n",
        "\n",
        "min_length_review = df_xtrain.loc[min_length_index, 'reviewText']\n",
        "max_length_review = df_xtrain.loc[max_length_index, 'reviewText']\n",
        "\n",
        "print(\"Review with Minimum Length:\\n\", min_length_review)\n",
        "print(\"\\nReview with Maximum Length:\\n\", max_length_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbmJlLvtRGP3",
        "outputId": "00bf3e68-6f47-4c78-d41e-892cfef87927"
      },
      "outputs": [],
      "source": [
        "max_tokens = 2000\n",
        "sentence_length = 400 #around the length of the 90th percentile\n",
        "encoder = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode='int',  \n",
        "    output_sequence_length=sentence_length)  \n",
        "\n",
        "encoder.adapt(df_xtrain['reviewText'].values)  \n",
        "\n",
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy8Gf0OCFnav",
        "outputId": "05701b53-7a8c-4031-cf38-f88d62fe4865"
      },
      "outputs": [],
      "source": [
        "example_text = df_xtrain['reviewText'].iloc[0] \n",
        "encoded_example = encoder([example_text])[:3].numpy()\n",
        "print(df_xtrain['reviewText'].iloc[0])\n",
        "print(encoded_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tMWaQSpNoox",
        "outputId": "c2721761-03d9-4227-b618-6dd5cc6e27ed"
      },
      "outputs": [],
      "source": [
        "sample_input = \"your sample text s s s input very good\"\n",
        "\n",
        "encoded_sample = encoder(tf.constant([sample_input]))\n",
        "print(encoded_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkjdmBfBKw9k"
      },
      "source": [
        "Convert y to one hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBBk-fa0T-hK"
      },
      "outputs": [],
      "source": [
        "df_ytrain_one_hot = tf.keras.utils.to_categorical(df_ytrain - 1, num_classes=5)\n",
        "df_yval_one_hot = tf.keras.utils.to_categorical(df_yval - 1, num_classes=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "5aLYpaF88xhc",
        "outputId": "d4322138-b182-4042-ca46-ac3507cbea75"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=16,\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "99V4W2HEdHRP",
        "outputId": "fc59d620-b0bd-43c7-af0c-7c77d573a9e8"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "wandb.init(project= 'RNN Experiments 1',\n",
        "           name = 'Bidi LSTM(16),1 layer,')\n",
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=16,\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy','AUC','Precision','Recall'])\n",
        "\n",
        "history = model.fit(\n",
        "    df_xtrain['reviewText'],\n",
        "    df_ytrain_one_hot,\n",
        "    epochs=10,\n",
        "    validation_data=(df_xval['reviewText'], df_yval_one_hot),\n",
        "    callbacks = [WandbCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "wandb.init(project= 'RNN Experiments 1',\n",
        "           name = 'Bidi LSTM(256),1 layer,')\n",
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=256,\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256)),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy','AUC','Precision','Recall'])\n",
        "\n",
        "history = model.fit(\n",
        "    df_xtrain['reviewText'],\n",
        "    df_ytrain_one_hot,\n",
        "    epochs=10,\n",
        "    validation_data=(df_xval['reviewText'], df_yval_one_hot),\n",
        "    callbacks = [WandbCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "wandb.init(project= 'RNN Experiments 1',\n",
        "           name = 'Bidi LSTM(256),1 layer,')\n",
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=256,\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256)),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy','AUC','Precision','Recall'])\n",
        "\n",
        "history = model.fit(\n",
        "    df_xtrain['reviewText'],\n",
        "    df_ytrain_one_hot,\n",
        "    epochs=30,\n",
        "    validation_data=(df_xval['reviewText'], df_yval_one_hot),\n",
        "    callbacks = [WandbCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "wandb.init(project= 'RNN Experiments 1',\n",
        "           name = 'Bidi LSTM(512), Embedding = 256, T= 2000, Len = 400')\n",
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=256,\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512)),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy','AUC','Precision','Recall'])\n",
        "\n",
        "history = model.fit(\n",
        "    df_xtrain['reviewText'],\n",
        "    df_ytrain_one_hot,\n",
        "    epochs=30,\n",
        "    validation_data=(df_xval['reviewText'], df_yval_one_hot),\n",
        "    callbacks = [WandbCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "wandb.init(project= 'RNN Experiments 1',\n",
        "           name = 'Bidi LSTM(512), Embedding = 512, T= 2000, Len = 400')\n",
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=512,\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512)),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy','AUC','Precision','Recall'])\n",
        "\n",
        "history = model.fit(\n",
        "    df_xtrain['reviewText'],\n",
        "    df_ytrain_one_hot,\n",
        "    epochs=30,\n",
        "    validation_data=(df_xval['reviewText'], df_yval_one_hot),\n",
        "    callbacks = [WandbCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "wandb.init(project= 'RNN Experiments 1',\n",
        "           name = 'LSTM(256), Embedding = 128, T= 2000, Len = 400')\n",
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=128,\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.LSTM(256),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy','AUC','Precision','Recall'])\n",
        "\n",
        "history = model.fit(\n",
        "    df_xtrain['reviewText'],\n",
        "    df_ytrain_one_hot,\n",
        "    epochs=30,\n",
        "    validation_data=(df_xval['reviewText'], df_yval_one_hot),\n",
        "    callbacks = [WandbCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "wandb.init(project= 'RNN Experiments 1',\n",
        "           name = 'Bidi GRU(512), Embedding = 256, 60000, T= 2000, Len = 400')\n",
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=256,\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(512)),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy','AUC','Precision','Recall'])\n",
        "\n",
        "history = model.fit(\n",
        "    df_xtrain['reviewText'],\n",
        "    df_ytrain_one_hot,\n",
        "    epochs=30,\n",
        "    validation_data=(df_xval['reviewText'], df_yval_one_hot),\n",
        "    callbacks = [WandbCallback()])\n",
        "\n",
        "model.save(\"model_navn.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "wandb.init(project= 'RNN Experiments 1',\n",
        "           name = 'Bidi GRU(512), Embedding = 128, 60000, T= 500, Len = 200')\n",
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=128,\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(512)),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy','AUC','Precision','Recall'])\n",
        "\n",
        "history = model.fit(\n",
        "    df_xtrain['reviewText'],\n",
        "    df_ytrain_one_hot,\n",
        "    epochs=30,\n",
        "    validation_data=(df_xval['reviewText'], df_yval_one_hot),\n",
        "    callbacks = [WandbCallback()])\n",
        "\n",
        "model.save(\"model_navn.keras\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
